{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afd2082a-83da-4104-916a-2791150c4a31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import LongType, StringType, BooleanType, TimestampType, IntegerType, ShortType\n",
    "from delta.tables import DeltaTable\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import col, regexp_replace, sha2, when, lit, uuid\n",
    "\n",
    "CATALOGO_ORIGEM = \"v_credit\"\n",
    "SCHEMA_ORIGEM = \"bronze\"\n",
    "TABELA_ORIGEM = \"chamados_hora\"\n",
    "\n",
    "CATALOGO_DESTINO = \"v_credit\"\n",
    "SCHEMA_DESTINO = \"silver\"\n",
    "TABELA_DESTINO = \"tb_chamado_log\"\n",
    "TABELA_INVALIDOS_DESTINO = \"tb_chamado_log_invalidos\"\n",
    "\n",
    "nome_tabela_origem = f\"{CATALOGO_ORIGEM}.{SCHEMA_ORIGEM}.{TABELA_ORIGEM}\"\n",
    "nome_tabela_destino = f\"{CATALOGO_DESTINO}.{SCHEMA_DESTINO}.{TABELA_DESTINO}\"\n",
    "\n",
    "timestamp_atual = F.current_timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fec361b6-665e-43e6-a4fb-ebece5f1c3d7",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1763932149676}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import LongType, TimestampType, StringType\n",
    "\n",
    "df_chamados_hora = spark.table(\"v_credit.bronze.chamados_hora\") \n",
    "\n",
    "tb_chamado_log_limpo = (\n",
    "    df_chamados_hora\n",
    "    .withColumnRenamed(\"id_chamado\", \"cd_chamado\")\n",
    "    .withColumnRenamed(\"id_cliente\", \"cd_cliente\")\n",
    "    .withColumnRenamed(\"hora_abertura_chamado\", \"dh_abertura\")\n",
    "    .withColumnRenamed(\"hora_inicio_atendimento\", \"dh_inicio\")\n",
    "    .withColumnRenamed(\"hora_finalizacao_atendimento\", \"dh_fim\")\n",
    "    .withColumnRenamed(\"ingestion_timestamp\", \"dt_ingestion\")\n",
    "    .withColumnRenamed(\"origem\", \"dc_origem\")\n",
    "    \n",
    "    .withColumn(\"cd_chamado\", col(\"cd_chamado\").cast(LongType()))\n",
    "    .withColumn(\"cd_cliente\", col(\"cd_cliente\").cast(StringType()))\n",
    "    \n",
    "    .withColumn(\"dh_abertura\", col(\"dh_abertura\"))\n",
    "    .withColumn(\"dh_inicio\", col(\"dh_inicio\"))\n",
    "    .withColumn(\"dh_fim\", col(\"dh_fim\"))\n",
    "    \n",
    "    .withColumn(\"dt_ingestion\", col(\"dt_ingestion\").cast(TimestampType()))\n",
    "    \n",
    "    .withColumn(\"dc_origem\", col(\"dc_origem\").cast(StringType()))\n",
    "    \n",
    "    # Drop columns\n",
    "    .drop(\"ctid_fivetran_id\", \"_fivetran_deleted\", \"_fivetran_synced\")\n",
    ")\n",
    "\n",
    "display(tb_chamado_log_limpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a49eacf8-203f-44c8-810f-a1f2d50c6153",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tb_chamado_log_limpo = (\n",
    "    tb_chamado_log_limpo.\n",
    "    withColumn(\"cd_cliente\", sha2(F.col(\"cd_cliente\").cast(StringType()), 256))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9875d968-985f-448b-b968-30bfbccc86df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, regexp_replace, to_timestamp\n",
    "from pyspark.sql.types import TimestampType\n",
    "\n",
    "def clean_and_convert_timestamp_col(df, raw_col_name):\n",
    "    DATE_FORMAT = \"dd/MM/yyyy HH:mm:ss\"\n",
    "    \n",
    "    df_cleaned = df.withColumn(\n",
    "        raw_col_name,\n",
    "        regexp_replace(col(raw_col_name), r'\\s?[\\W_]*s\\s?', ' ')\n",
    "    )\n",
    "\n",
    "    df_cleaned = df_cleaned.withColumn(\n",
    "        raw_col_name,\n",
    "        to_timestamp(col(raw_col_name), DATE_FORMAT).cast(TimestampType())\n",
    "    )\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "tb_chamado_log_validacao = clean_and_convert_timestamp_col(tb_chamado_log_limpo, \"dh_abertura\")\n",
    "tb_chamado_log_validacao = clean_and_convert_timestamp_col(tb_chamado_log_validacao, \"dh_inicio\")\n",
    "tb_chamado_log_validacao = clean_and_convert_timestamp_col(tb_chamado_log_validacao, \"dh_fim\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70981586-46f3-41f8-807f-972042b02bed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "deltaTable = DeltaTable.forName(spark, nome_tabela_destino)\n",
    "\n",
    "deltaTable.alias(\"target\") \\\n",
    "    .merge(\n",
    "        source=tb_chamado_log_validacao.alias(\"source\"),\n",
    "        condition=f\"target.cd_chamado = source.cd_chamado\"\n",
    "    ) \\\n",
    "    .whenMatchedUpdateAll() \\\n",
    "    .whenNotMatchedInsertAll() \\\n",
    "    .execute()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "src_tb_chamado_log",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
